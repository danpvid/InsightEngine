# ğŸ“¤ Upload de DataSets (CSV) - DocumentaÃ§Ã£o

## ğŸ¯ VisÃ£o Geral

O sistema suporta upload de arquivos CSV grandes usando **streaming** para evitar estouro de memÃ³ria. Os arquivos sÃ£o salvos com nomes seguros baseados em GUID para prevenir colisÃµes e ataques de path traversal.

## ğŸ” SeguranÃ§a Implementada

### 1. **PrevenÃ§Ã£o de Path Traversal**
- âœ… SanitizaÃ§Ã£o automÃ¡tica de nomes de arquivos
- âœ… RemoÃ§Ã£o de caracteres especiais e caminhos relativos
- âœ… ValidaÃ§Ã£o usando `Path.GetFileName()`
- âœ… Nome do arquivo armazenado: `{GUID}.csv`

### 2. **ValidaÃ§Ã£o de Arquivos**
- âœ… Apenas arquivos `.csv` sÃ£o permitidos
- âœ… ValidaÃ§Ã£o de Content-Type (text/csv, application/csv)
- âœ… Limite mÃ¡ximo: **500MB** por arquivo
- âœ… ValidaÃ§Ã£o no backend e nas configuraÃ§Ãµes do Kestrel

### 3. **Streaming para Arquivos Grandes**
- âœ… **Buffer de 80KB** para leitura/escrita eficiente
- âœ… **NÃ£o carrega o arquivo inteiro na memÃ³ria**
- âœ… Processamento em chunks
- âœ… Suporte para arquivos de vÃ¡rios GB sem problemas

## ğŸ“‹ Endpoint de Upload

### **POST** `/api/dataset/upload`

**AutenticaÃ§Ã£o:** Requer JWT Bearer Token

**Content-Type:** `multipart/form-data`

**ParÃ¢metros:**
- `file` (required): Arquivo CSV

**Limites:**
- Tamanho mÃ¡ximo: 500MB
- Formato: apenas `.csv`

### Exemplo de RequisiÃ§Ã£o

#### cURL
```bash
curl -X POST "https://localhost:5001/api/dataset/upload" \
  -H "Authorization: Bearer {seu_token}" \
  -F "file=@/path/to/seu-arquivo.csv"
```

#### PowerShell
```powershell
$token = "seu_token_jwt"
$filePath = "C:\caminho\para\arquivo.csv"

$headers = @{
    "Authorization" = "Bearer $token"
}

$form = @{
    file = Get-Item -Path $filePath
}

Invoke-RestMethod -Uri "https://localhost:5001/api/dataset/upload" `
    -Method Post `
    -Headers $headers `
    -Form $form
```

#### C# HttpClient
```csharp
using var client = new HttpClient();
client.DefaultRequestHeaders.Authorization = 
    new AuthenticationHeaderValue("Bearer", token);

using var content = new MultipartFormDataContent();
using var fileStream = File.OpenRead("arquivo.csv");
using var streamContent = new StreamContent(fileStream);

streamContent.Headers.ContentType = new MediaTypeHeaderValue("text/csv");
content.Add(streamContent, "file", "arquivo.csv");

var response = await client.PostAsync(
    "https://localhost:5001/api/dataset/upload", 
    content);
```

### Resposta de Sucesso (200 OK)

```json
{
  "success": true,
  "message": "Arquivo enviado com sucesso.",
  "data": {
    "datasetId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
    "originalFileName": "vendas-2024.csv",
    "storedPath": "C:\\uploads\\3fa85f64-5717-4562-b3fc-2c963f66afa6.csv",
    "fileSizeInBytes": 104857600,
    "fileSizeMB": 100.0,
    "createdAt": "2026-02-14T15:30:00Z"
  }
}
```

### Resposta de Erro (400 Bad Request)

```json
{
  "success": false,
  "message": "Apenas arquivos CSV sÃ£o permitidos."
}
```

### Resposta de Erro (413 Payload Too Large)

```json
{
  "success": false,
  "message": "Arquivo muito grande. Tamanho mÃ¡ximo permitido: 500MB"
}
```

## ğŸ“Š Outros Endpoints

### **GET** `/api/dataset`
Lista todos os datasets

**Resposta:**
```json
{
  "success": true,
  "data": [
    {
      "datasetId": "guid",
      "originalFileName": "arquivo.csv",
      "storedFileName": "guid.csv",
      "fileSizeInBytes": 12345,
      "fileSizeMB": 0.01,
      "createdAt": "2026-02-14T15:30:00Z"
    }
  ]
}
```

### **GET** `/api/dataset/{id}`
ObtÃ©m informaÃ§Ãµes de um dataset especÃ­fico

**Resposta:**
```json
{
  "success": true,
  "data": {
    "datasetId": "guid",
    "originalFileName": "arquivo.csv",
    "storedFileName": "guid.csv",
    "storedPath": "/path/to/guid.csv",
    "fileSizeInBytes": 12345,
    "fileSizeMB": 0.01,
    "contentType": "text/csv",
    "createdAt": "2026-02-14T15:30:00Z",
    "updatedAt": null
  }
}
```

## âš™ï¸ ConfiguraÃ§Ã£o

### appsettings.json

```json
{
  "FileStorage": {
    "BasePath": "uploads"
  }
}
```

### Alterar Limite de Tamanho

Para alterar o limite de 500MB, edite:

**Program.cs:**
```csharp
builder.Services.Configure<KestrelServerOptions>(options =>
{
    options.Limits.MaxRequestBodySize = 1024 * 1024 * 1024; // 1GB
});

builder.Services.Configure<FormOptions>(options =>
{
    options.MultipartBodyLengthLimit = 1024 * 1024 * 1024; // 1GB
});
```

**DataSetController.cs:**
```csharp
private const long MaxFileSize = 1024L * 1024 * 1024; // 1GB
```

## ğŸ”§ OtimizaÃ§Ãµes para Performance

### 1. **Buffer Size**
- PadrÃ£o: 80KB (81920 bytes)
- Otimizado para balance entre memÃ³ria e velocidade
- AjustÃ¡vel no `FileStorageService`

### 2. **Async/Await**
- Todo I/O Ã© assÃ­ncrono
- NÃ£o bloqueia threads durante upload
- Suporta cancelamento (`CancellationToken`)

### 3. **Streaming**
- Arquivo nunca Ã© carregado inteiramente na memÃ³ria
- Processamento chunk por chunk
- EscalÃ¡vel para arquivos de vÃ¡rios GB

### 4. **Logging**
- Log a cada 10MB processados
- Monitoramento de progresso
- Facilita debugging

## ğŸ—„ï¸ Estrutura no Banco de Dados

### Tabela: DataSets

```sql
CREATE TABLE DataSets (
    Id UNIQUEIDENTIFIER PRIMARY KEY,
    OriginalFileName NVARCHAR(255) NOT NULL,
    StoredFileName NVARCHAR(255) NOT NULL UNIQUE,
    StoredPath NVARCHAR(500) NOT NULL,
    FileSizeInBytes BIGINT NOT NULL,
    ContentType NVARCHAR(100) NOT NULL,
    CreatedAt DATETIME2 NOT NULL,
    UpdatedAt DATETIME2 NULL
);
```

## ğŸ“ Estrutura de Arquivos

```
InsightEngine/
â”œâ”€â”€ uploads/                                    # Pasta de armazenamento
â”‚   â”œâ”€â”€ {guid-1}.csv                           # Arquivo armazenado
â”‚   â”œâ”€â”€ {guid-2}.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ InsightEngine.API/
â”‚   â”‚   â””â”€â”€ Controllers/
â”‚   â”‚       â””â”€â”€ DataSetController.cs           # Endpoints HTTP
â”‚   â”œâ”€â”€ InsightEngine.Application/
â”‚   â”‚   â”œâ”€â”€ Commands/DataSet/
â”‚   â”‚   â”‚   â”œâ”€â”€ UploadDataSetCommand.cs        # Comando
â”‚   â”‚   â”‚   â””â”€â”€ UploadDataSetCommandHandler.cs # Handler
â”‚   â”‚   â””â”€â”€ Models/DataSet/
â”‚   â”‚       â””â”€â”€ DataSetUploadOutputModel.cs    # Output model
â”‚   â”œâ”€â”€ InsightEngine.Domain/
â”‚   â”‚   â”œâ”€â”€ Entities/
â”‚   â”‚   â”‚   â””â”€â”€ DataSet.cs                     # Entidade
â”‚   â”‚   â””â”€â”€ Interfaces/
â”‚   â”‚       â”œâ”€â”€ IDataSetRepository.cs          # Interface do repositÃ³rio
â”‚   â”‚       â””â”€â”€ IFileStorageService.cs         # Interface do serviÃ§o
â”‚   â””â”€â”€ InsightEngine.Infra.Data/
â”‚       â”œâ”€â”€ Repositories/
â”‚       â”‚   â””â”€â”€ DataSetRepository.cs           # ImplementaÃ§Ã£o
â”‚       â”œâ”€â”€ Services/
â”‚       â”‚   â””â”€â”€ FileStorageService.cs          # ServiÃ§o de storage
â”‚       â””â”€â”€ Mappings/
â”‚           â””â”€â”€ DataSetMapping.cs              # Mapeamento EF Core
```

## ğŸš€ Testando no Swagger

1. Execute a aplicaÃ§Ã£o: `dotnet run --project src/InsightEngine.API`
2. Acesse: `https://localhost:5001/swagger`
3. FaÃ§a login em `/api/auth/login`
4. Clique no botÃ£o **Authorize** ğŸ”’
5. Cole o token obtido no formato: `Bearer {token}`
6. VÃ¡ para `/api/dataset/upload`
7. Clique em **Try it out**
8. Escolha um arquivo CSV
9. Clique em **Execute**

## âš ï¸ ConsideraÃ§Ãµes de ProduÃ§Ã£o

### 1. **Armazenamento**
- âœ… Para produÃ§Ã£o, considere usar cloud storage (Azure Blob, AWS S3)
- âœ… Implemente polÃ­tica de backup
- âœ… Configure retenÃ§Ã£o de arquivos

### 2. **Escalabilidade**
- âœ… Use CDN para distribuiÃ§Ã£o
- âœ… Considere compressÃ£o (gzip)
- âœ… Implemente queue para processamento assÃ­ncrono

### 3. **SeguranÃ§a**
- âœ… Escaneie arquivos para malware
- âœ… Implemente rate limiting
- âœ… Adicione validaÃ§Ã£o de conteÃºdo CSV
- âœ… Configure CORS adequadamente

### 4. **Monitoramento**
- âœ… Monitor disk space
- âœ… Track upload metrics
- âœ… Alert on failures
- âœ… Log audit trail

## ğŸ“ Exemplo de Uso Completo

```csharp
// 1. Obter token JWT
POST /api/auth/login
{
  "email": "user@example.com",
  "password": "senha123"
}

// 2. Upload do CSV
POST /api/dataset/upload
Headers: Authorization: Bearer {token}
Body: multipart/form-data with file

// 3. Verificar upload
GET /api/dataset/{datasetId}
Headers: Authorization: Bearer {token}

// 4. Listar todos
GET /api/dataset
Headers: Authorization: Bearer {token}
```

---

**Sistema pronto para receber arquivos CSV grandes de forma segura e eficiente! ğŸ‰**
