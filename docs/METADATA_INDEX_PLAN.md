# Metadata Index Plan

## Purpose
Build a deterministic metadata indexing pipeline for single-table datasets to power fast exploratory UX in a Splunk-style experience.

## Current Baseline (Discovery)
- Dataset profiling is generated by `CsvProfiler` and exposed through existing dataset/profile endpoints.
- Chart recommendations are generated by `RecommendationEngine` using inferred roles and profile stats.
- DuckDB is already used for chart execution, raw rows querying, and field stats.
- Angular dataset routes currently include upload, recommendations, and chart viewer pages.

## Target Index Artifacts
- `DatasetIndex`
  - `datasetId`, `builtAt`, `version`, `rowCount`, `columnCount`
  - `quality`, `columns`, `candidateKeys`, `correlations`, `tags`, `stats`, `limits`
- `ColumnIndex`
  - per-column inferred type, completeness/cardinality metrics, typed stats, semantic tags
- `CorrelationEdge`
  - ranked pairwise relationships with capped/top-K storage
- `KeyCandidate`
  - candidate key combinations with confidence metrics

## Storage & Cache Strategy
- Persist index artifacts as JSON alongside dataset metadata.
- Keep status file lifecycle (`building`, `ready`, `failed`) for async-friendly UX.
- Add in-memory + file-based cache for index reads with TTL.

## API Surface (Additive)
- `POST /api/v1/datasets/{datasetId}/index:build`
- `GET /api/v1/datasets/{datasetId}/index`
- `GET /api/v1/datasets/{datasetId}/index/status`

## Frontend Direction
- Add `Explore` route: `/datasets/:datasetId/explore`.
- Build field explorer + facets + distribution + correlation panels backed by metadata index.
- Preserve existing chart/recommendation routes and endpoint behavior.

## Performance & Safety Constraints
- Never compute full NxN correlations without caps.
- Limit correlation columns and store only top-K edges per column.
- Use deterministic DuckDB analytics with sampling thresholds for heavy operations.
- Validate/whitelist column names in all dynamic SQL paths.

