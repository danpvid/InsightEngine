# Dia 2 - Dataset Profiling (Motor do InsightEngine)

## Objetivo

Implementar o primeiro "motor" do InsightEngine: um sistema que l√™ CSVs, infere o schema automaticamente e retorna um "data profile" que usu√°rios de neg√≥cio conseguem entender.

## Endpoints Implementados

### 1. Upload de Dataset
**POST** `/api/v1/datasets`

Recebe um arquivo CSV, salva com identificador √∫nico e retorna metadata.

#### Request
```http
POST /api/v1/datasets HTTP/1.1
Content-Type: multipart/form-data
Authorization: Bearer {token}

file: vendas.csv
```

#### Response (201 Created)
```json
{
  "success": true,
  "message": "Arquivo enviado com sucesso.",
  "data": {
    "datasetId": "a3f7b2c1-5d4e-4a9b-8c3f-1e2d3c4b5a6f",
    "originalFileName": "vendas.csv",
    "storedFileName": "a3f7b2c1-5d4e-4a9b-8c3f-1e2d3c4b5a6f.csv",
    "sizeBytes": 245678,
    "createdAtUtc": "2026-02-14T03:00:00Z"
  }
}
```

#### Valida√ß√µes
- ‚ùå `file == null` ‚Üí 400 Bad Request
- ‚ùå `file.Length == 0` ‚Üí 400 Bad Request
- ‚ùå `extens√£o != .csv` ‚Üí 400 Bad Request
- ‚ùå `file.Length > 20MB` ‚Üí 413 Payload Too Large (configur√°vel)

#### Seguran√ßa
- ‚úÖ Arquivo salvo como `{datasetId}.csv` para evitar colis√µes
- ‚úÖ Previne path traversal attacks
- ‚úÖ Streaming para arquivos grandes (n√£o carrega na mem√≥ria)

---

### 2. Profile do Dataset
**GET** `/api/v1/datasets/{datasetId}/profile`

Analisa o CSV e retorna schema inferido com estat√≠sticas.

#### Request
```http
GET /api/v1/datasets/a3f7b2c1-5d4e-4a9b-8c3f-1e2d3c4b5a6f/profile HTTP/1.1
Authorization: Bearer {token}
```

#### Response (200 OK)
```json
{
  "success": true,
  "data": {
    "datasetId": "a3f7b2c1-5d4e-4a9b-8c3f-1e2d3c4b5a6f",
    "rowCount": 12450,
    "sampleSize": 5000,
    "columns": [
      {
        "name": "sale_date",
        "inferredType": "Date",
        "nullRate": 0.0,
        "distinctCount": 365,
        "topValues": ["2025-01-01", "2025-01-02", "2025-01-03"]
      },
      {
        "name": "amount",
        "inferredType": "Number",
        "nullRate": 0.01,
        "distinctCount": 4200,
        "topValues": ["19.9", "29.9", "9.9"]
      },
      {
        "name": "status",
        "inferredType": "Category",
        "nullRate": 0.0,
        "distinctCount": 3,
        "topValues": ["completed", "pending", "cancelled"]
      },
      {
        "name": "is_paid",
        "inferredType": "Boolean",
        "nullRate": 0.0,
        "distinctCount": 2,
        "topValues": ["true", "false"]
      },
      {
        "name": "description",
        "inferredType": "String",
        "nullRate": 0.15,
        "distinctCount": 8900,
        "topValues": ["Product A", "Product B", "Product C"]
      }
    ]
  }
}
```

---

## Tipos Inferidos (Heur√≠stica Simples e Eficaz)

### 1. Boolean
**Condi√ß√£o:** 90%+ dos valores parseia como boolean

**Valores aceitos:**
- `true`, `false`
- `yes`, `no`
- `1`, `0`
- `t`, `f`
- `y`, `n`
- `sim`, `n√£o`, `nao`

**Exemplo:**
```csv
is_active
true
false
true
1
0
yes
```
‚Üí **Boolean** ‚úÖ

---

### 2. Date
**Condi√ß√£o:** 90%+ dos valores parseia como DateTime

**Formatos suportados:**
- ISO: `yyyy-MM-dd`
- BR: `dd/MM/yyyy`
- US: `MM/dd/yyyy`
- Compacto: `yyyyMMdd`
- Com separadores: `yyyy/MM/dd`, `dd-MM-yyyy`, `MM-dd-yyyy`

**Exemplo:**
```csv
sale_date
2025-01-01
2025-01-02
2025-01-03
```
‚Üí **Date** ‚úÖ

---

### 3. Number
**Condi√ß√£o:** 90%+ dos valores parseia como decimal

**Formatos aceitos:**
- Inteiros: `123`, `-456`
- Decimais: `19.99`, `-45.67`
- Com separador de milhar: `1,234.56` (removido automaticamente)
- Nota√ß√£o cient√≠fica: `1.23e5`

**Exemplo:**
```csv
amount
19.90
29.90
1,234.56
-45.67
```
‚Üí **Number** ‚úÖ

---

### 4. Category
**Condi√ß√£o:** Baixa cardinalidade (poucos valores distintos)

**Regra:** `distinctCount <= max(20, rowCount * 0.05)`

Ou seja:
- Se dataset tem < 400 linhas: limite = 20 valores distintos
- Se dataset tem ‚â• 400 linhas: limite = 5% do total

**Exemplo:**
```csv
status
completed
pending
cancelled
completed
completed
pending
```
‚Üí **Category** ‚úÖ (apenas 3 valores distintos)

---

### 5. String
**Condi√ß√£o:** Default quando nenhum outro tipo se aplica

**Casos:**
- Alta cardinalidade (muitos valores distintos)
- Texto livre
- Valores mistos que n√£o atingem 90% de threshold

**Exemplo:**
```csv
description
Produto de alta qualidade para uso profissional
Item importado com certifica√ß√£o internacional
Mercadoria nacional com garantia estendida
```
‚Üí **String** ‚úÖ

---

## Performance e Otimiza√ß√µes

### Amostragem Inteligente
- **Sample size:** 5.000 linhas (configur√°vel em `appsettings.json`)
- **Infer√™ncia de tipo:** baseada na amostra (r√°pido)
- **Contagem total:** varre arquivo completo sem carregar em mem√≥ria
- **Trade-off:** Infer√™ncia r√°pida vs. precis√£o absoluta

### Limites de Mem√≥ria
- **Distinct tracking:** m√°ximo 10.000 valores distintos por coluna
- **Top values:** m√°ximo 1.000 valores √∫nicos rastreados
- **Quando o limite √© atingido:** para de rastrear e retorna estimativa

### Streaming
- **Upload:** n√£o carrega arquivo inteiro na mem√≥ria
- **Profile:** processa linha por linha com buffer de 80KB
- **Parser:** CsvHelper para robustez (aspas, v√≠rgulas internas, etc.)

---

## Configura√ß√µes

### appsettings.json
```json
{
  "UploadSettings": {
    "BasePath": "uploads",
    "MaxFileSizeBytes": 20971520,
    "ProfileSampleSize": 5000
  }
}
```

### Limites Configur√°veis
| Par√¢metro | Valor Padr√£o | Descri√ß√£o |
|-----------|--------------|-----------|
| `MaxFileSizeBytes` | 20 MB | Tamanho m√°ximo de upload |
| `ProfileSampleSize` | 5.000 linhas | Linhas para infer√™ncia |
| `MaxDistinctTracking` | 10.000 | Limite de valores distintos |
| `TopValuesCount` | 3 | Top N valores mais frequentes |
| `TypeInferenceThreshold` | 90% | M√≠nimo para inferir tipo |

---

## Arquitetura Implementada

### Domain Layer
```
Domain/
‚îú‚îÄ‚îÄ Enums/
‚îÇ   ‚îî‚îÄ‚îÄ InferredType.cs (Number, Date, Boolean, String, Category)
‚îú‚îÄ‚îÄ ValueObjects/
‚îÇ   ‚îú‚îÄ‚îÄ ColumnProfile.cs (Name, InferredType, NullRate, DistinctCount, TopValues)
‚îÇ   ‚îî‚îÄ‚îÄ DatasetProfile.cs (DatasetId, RowCount, SampleSize, Columns)
‚îú‚îÄ‚îÄ Interfaces/
‚îÇ   ‚îî‚îÄ‚îÄ ICsvProfiler.cs
‚îî‚îÄ‚îÄ Settings/
    ‚îî‚îÄ‚îÄ UploadSettings.cs
```

### Infrastructure Layer
```
Infra.Data/
‚îî‚îÄ‚îÄ Services/
    ‚îî‚îÄ‚îÄ CsvProfiler.cs (heur√≠sticas de infer√™ncia com CsvHelper)
```

### API Layer
```
API/
‚îî‚îÄ‚îÄ Controllers/V1/
    ‚îî‚îÄ‚îÄ DataSetController.cs (POST /, GET /{id}/profile)
```

---

## Fluxo de Uso Completo

### 1. Upload
```bash
curl -X POST "https://localhost:5000/api/v1/datasets" \
  -H "Authorization: Bearer {token}" \
  -F "file=@vendas.csv"
```

**Resposta:**
```json
{
  "success": true,
  "data": {
    "datasetId": "a3f7b2c1-5d4e-4a9b-8c3f-1e2d3c4b5a6f",
    ...
  }
}
```

### 2. Profile
```bash
curl -X GET "https://localhost:5000/api/v1/datasets/a3f7b2c1-5d4e-4a9b-8c3f-1e2d3c4b5a6f/profile" \
  -H "Authorization: Bearer {token}"
```

**Resposta:**
```json
{
  "success": true,
  "data": {
    "rowCount": 12450,
    "sampleSize": 5000,
    "columns": [...]
  }
}
```

---

## Testing no Swagger

### Passo 1: Autenticar
1. Abra `https://localhost:5000/swagger`
2. POST `/api/v1/auth/login` com credenciais
3. Copie o token JWT
4. Clique no bot√£o üîí "Authorize" no topo
5. Cole: `Bearer {token}`

### Passo 2: Upload
1. POST `/api/v1/datasets`
2. Clique em "Try it out"
3. Selecione um CSV de teste
4. Execute
5. **Copie o `datasetId` da resposta**

### Passo 3: Profile
1. GET `/api/v1/datasets/{datasetId}/profile`
2. Clique em "Try it out"
3. Cole o `datasetId` copiado
4. Execute
5. **Confira os tipos inferidos** ‚úÖ

---

## Checklist de Valida√ß√£o (Definition of Done)

‚úÖ **Upload funciona:**
- POST `/api/v1/datasets` retorna 201 Created
- Arquivo salvo como `{datasetId}.csv`
- Metadata completo no response

‚úÖ **Profile funciona:**
- GET `/api/v1/datasets/{datasetId}/profile` retorna 200 OK
- Tipos inferidos corretamente:
  - Datas ‚Üí `Date`
  - N√∫meros ‚Üí `Number`
  - Booleanos ‚Üí `Boolean`
  - Baixa cardinalidade ‚Üí `Category`
  - Alta cardinalidade ‚Üí `String`

‚úÖ **Estat√≠sticas corretas:**
- `nullRate` faz sentido
- `distinctCount` coerente
- `topValues` mostra os 3 mais frequentes
- `sampleSize` e `rowCount` presentes

‚úÖ **Performance:**
- Upload de 20MB funciona sem timeout
- Profile de 10k+ linhas retorna em < 5 segundos
- Mem√≥ria n√£o estoura com arquivos grandes

‚úÖ **Valida√ß√µes:**
- CSV-only enforcement (400 para outros formatos)
- Limite de 20MB respeitado (413 quando excede)
- Arquivo n√£o encontrado retorna 404

---

## Pr√≥ximos Passos (Dia 3+)

1. **Transforma√ß√µes:** Filtros, agrega√ß√µes, joins
2. **Visualiza√ß√µes:** Gr√°ficos autom√°ticos baseados no tipo
3. **ML:** Detec√ß√£o de anomalias, correla√ß√µes
4. **Export:** Salvar profile como JSON/PDF
5. **Suporte XLSX:** Ler Excel al√©m de CSV

---

## Tecnologias Utilizadas

- **CsvHelper 33.1.0:** Parser robusto de CSV
- **CsvProfiler:** Heur√≠sticas de infer√™ncia de tipo
- **Streaming:** FileStream com buffer de 80KB
- **CQRS:** Separa√ß√£o de comandos (upload) e queries (profile)
- **Clean Architecture:** Domain ‚Üí Infra ‚Üí API

---

## Observa√ß√µes do MVP

### Decis√µes de Simplicidade
1. **CSV only:** XLSX vir√° depois
2. **Sample size fixo:** 5.000 linhas (configur√°vel, mas fixo no MVP)
3. **RowCount = amostra + contagem sem parse:** N√£o faz parse completo agora
4. **Heur√≠sticas simples:** 90% threshold √© "good enough"
5. **Sem cache:** Profile calculado on-demand (pode cachear depois)

### Trade-offs Conscientes
| Decis√£o | Trade-off | Justificativa |
|---------|-----------|---------------|
| Amostragem de 5k linhas | Precis√£o vs. Velocidade | MVP precisa ser r√°pido |
| 90% threshold | Rigor vs. Pragmatismo | Cobre 90%+ dos casos reais |
| Distinct limit 10k | Mem√≥ria vs. Completude | Previne OOM em colunas com alta cardinalidade |
| Top 3 values | Informa√ß√£o vs. Simplicidade | Suficiente para entender distribui√ß√£o |

---

**Status:** ‚úÖ Dia 2 Completo - Motor de Profiling Funcionando!
